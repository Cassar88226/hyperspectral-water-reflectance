{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6hJWXDFriBoh"
      },
      "source": [
        "# TensorFlow Model for Chlorophyll-A and SPM Prediction from HYPSTAR Multispectral Imagery\n",
        "\n",
        "In this notebook, we implement a TensorFlow model for predicting Chlorophyll-A (g/m³) and Suspended Particulate Matter (SPM) (g/m³) from multispectral imagery obtained from the HYPSTAR sensor. This model aims to leverage the rich information embedded in the multispectral data to accurately estimate concentrations of Chlorophyll-A and SPM in the target environment.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "x-YpK42iZK8u"
      },
      "outputs": [],
      "source": [
        "# importing all the necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Dense,Conv1D,Flatten\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.optimizers import Adam\n",
        "from keras.models import load_model\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import mean_squared_error,r2_score,mean_absolute_error"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yb7kR_0pir0s"
      },
      "source": [
        "# Loading Data into Pandas DataFrames (DF)\n",
        "\n",
        "In this section, we load data into Pandas DataFrames for further analysis. Prior to loading, description rows were systematically removed from all CSV files using Microsoft Excel. This preprocessing step, completed in approximately five minutes, simplifies the subsequent loading process into DataFrames.\n",
        "\n",
        "This data preparation approach ensures a streamlined and efficient loading procedure, facilitating a more straightforward exploration and analysis of the datasets.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "JWRauHwgZNnH"
      },
      "outputs": [],
      "source": [
        "#Dataframe for HYPSTAR imagery\n",
        "df_l2a = pd.read_csv(\"HYPSTAR_W_BSBE_L2A_REFL_20210203_20220803_v1.csv\", skiprows=17)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "4JTZk6i1ZoF2"
      },
      "outputs": [],
      "source": [
        "#Dataframe for chlorophyll found by Ruddick paper\n",
        "df_chla_crat = pd.read_csv(\"HYPSTAR_W_BSBE_CHLA_CRAT_20210203_20220803_v1.csv\", skiprows=18)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "MvR9wrGZazhh"
      },
      "outputs": [],
      "source": [
        "#Dataframe for chlorophyll found by Simis paper\n",
        "df_chla_simis = pd.read_csv(\"HYPSTAR_W_BSBE_CHLA_SIMIS_20210203_20220803_v1.csv\", skiprows=18)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "Q-x7pLn3a1e5"
      },
      "outputs": [],
      "source": [
        "#Dataframe for spm700\n",
        "df_spm= pd.read_csv(\"HYPSTAR_W_BSBE_SPM_20210203_20220803_v1.csv\", skiprows=18)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P_U3AJnVkhLf"
      },
      "source": [
        "# Preprocessing the data\n",
        "This step is necessary to input the data into the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "lFLkWnaCbu8l"
      },
      "outputs": [],
      "source": [
        "# Dropping the datetime column as it's not needed anymore\n",
        "X_data = df_l2a.drop(['DateTime'],axis = 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BUCoYJMCkHCC"
      },
      "source": [
        "## Wavelength Limitation for Machine Learning Dataset\n",
        "\n",
        "The next cell contains code designed to prompt the user for input regarding the limitation of input wavelengths for a tensorflow model. The user is given the option to specify a range of wavelengths or proceed with the default settings.\n",
        "\n",
        "### Code Explanation\n",
        "\n",
        "1. **User Prompt:** The user is prompted to select whether they want to limit the input wavelengths to a specific range.\n",
        "\n",
        "2. **Options Display:** The available options for limiting wavelengths (Y) or proceeding with the default (N) are displayed.\n",
        "\n",
        "3. **Input and Processing:**\n",
        "   - If the user chooses to limit wavelengths:\n",
        "     - The lower and upper bounds of the wavelength range are obtained from the user.\n",
        "     - A message is displayed indicating the range being considered.\n",
        "     - Wavelengths within the specified range are identified and stored in `selected_columns`.\n",
        "     - If no wavelengths are found in the range, an error message is displayed.\n",
        "     - Otherwise, the dataset is updated to include only the selected columns, and a confirmation message is displayed.\n",
        "\n",
        "   - If the user chooses not to limit wavelengths:\n",
        "     - All columns in the original dataset (`X_data`) are considered, and the user is informed that the dataset will proceed without limitations.\n",
        "\n",
        "### Usage\n",
        "\n",
        "- Execute the cell to run the code.\n",
        "- Follow the prompts to choose whether to limit wavelengths and, if applicable, provide the lower and upper bounds.\n",
        "\n",
        "### Notes\n",
        "\n",
        "- Ensure that the dataset (`X_data`) is defined and accessible before executing this cell.\n",
        "- The resulting dataset (`X_data`) is updated based on the user's choice.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y5sA69zzFrd_",
        "outputId": "b3183cb6-857f-4d7b-df4f-d434d0e8dc08"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Please select if you want to limit wavelengths to a specific range: \n",
            "Limiting: Y\n",
            "Default: Press any other key\n",
            "y\n",
            "Please enter the lower bound: 400\n",
            "Please enter the upper bound: 450\n",
            "Finding wavelengths between 400.0 and 450.0........\n",
            "Found 106 wavelengths\n",
            "Limited the dataset to 400.0 - 450.0\n"
          ]
        }
      ],
      "source": [
        "# Prompt the user to choose whether to limit wavelengths or not\n",
        "print(\"Please select if you want to limit wavelengths to a specific range: \")\n",
        "\n",
        "# Display options for limiting or not\n",
        "print(\"Limiting: Y\")\n",
        "print(\"Default: Press any other key\")\n",
        "\n",
        "# Initialize an empty list to store selected columns\n",
        "selected_columns = []\n",
        "\n",
        "# Get user input for their choice\n",
        "choice = input(\"\")\n",
        "\n",
        "# Check if the user wants to limit wavelengths\n",
        "if (choice.upper() == 'Y'):\n",
        "\n",
        "  # Get lower and upper bounds from the user\n",
        "  lower = float(input(\"Please enter the lower bound: \"))\n",
        "  upper = float(input(\"Please enter the upper bound: \"))\n",
        "\n",
        "  # Display a message indicating the range being considered\n",
        "  print(\"Finding wavelengths between {} and {}........\".format(lower, upper))\n",
        "\n",
        "  # Iterate through columns in the dataset\n",
        "  if lower and upper:\n",
        "    selected_columns = [col for col in X_data.columns if (float(col) >= lower and float(col) < upper)]\n",
        "\n",
        "  # Check if any wavelengths were found in the specified range\n",
        "  if not selected_columns:\n",
        "    print(\"Error! There is no wavelength in the specified range\")\n",
        "  else:\n",
        "    # Display the number of wavelengths found\n",
        "    print(\"Found {} wavelengths\".format(len(selected_columns)))\n",
        "\n",
        "    # Update the dataset to include only the selected columns\n",
        "    X_data = X_data[selected_columns]\n",
        "\n",
        "    # Display a message indicating the dataset has been limited\n",
        "    print(\"Limited the dataset to {} - {}\".format(lower, upper))\n",
        "\n",
        "else:\n",
        "  # If the user chooses not to limit, use all columns in the dataset\n",
        "  selected_columns = X_data.columns.to_list()\n",
        "  print(\"Going without limiting\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "35VsL5ofk6Cb"
      },
      "source": [
        "## Data Preprocessing for Chlorophyll-A Predictions\n",
        "\n",
        "In the preprocessing step of our dataset, we address the presence of two types of Chlorophyll-A predictions in the input. To enhance the model's robustness, we take the average of these predictions and utilize it as the consolidated input for the machine learning model.\n",
        "\n",
        "Additionally, to create a comprehensive dataset, we integrate the Chlorophyll-A and SPM700 columns with the existing dataset, denoted as `X_data`.\n",
        "\n",
        "### Processing Steps\n",
        "\n",
        "1. **Chlorophyll-A Averaging:**\n",
        "   - Two distinct types of Chlorophyll-A predictions are present in our input.\n",
        "   - We calculate the average of these predictions to create a singular and more representative input for the machine learning model.\n",
        "\n",
        "2. **Dataset Integration:**\n",
        "   - The Chlorophyll-A and SPM700 columns are seamlessly combined with the existing dataset (`X_data`).\n",
        "   - This integration ensures that the dataset is comprehensive and includes all relevant features for model training.\n",
        "\n",
        "### Importance and Considerations\n",
        "\n",
        "- Averaging Chlorophyll-A predictions enhances the model's ability to generalize across different types of predictions.\n",
        "- The inclusion of Chlorophyll-A and SPM700 columns in the dataset provides a holistic set of features for the machine learning model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "vIKfTEJmeS0V"
      },
      "outputs": [],
      "source": [
        "X_data['Chlorophyll-A'] =  (df_chla_crat['Chl_CratVC'] + df_chla_simis['Chl_SimisVC'] )/2 #Averaging the two Chlorophyll inputs and adding them to X_data\n",
        "X_data['SPM700'] = df_spm['SPM700'] # Adding SPM700 to X_data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iskWPeOQezAu",
        "outputId": "5558792e-69cc-47ba-9e0c-48d4369826d8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "400.24            0\n",
              "400.71            0\n",
              "401.18            0\n",
              "401.65            0\n",
              "402.13            0\n",
              "                 ..\n",
              "449.03            0\n",
              "449.51            0\n",
              "449.98            0\n",
              "Chlorophyll-A    35\n",
              "SPM700            0\n",
              "Length: 108, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "X_data.isna().sum() #Checking for null values, since the presence of null values can cause model to generate errors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "ya7Ccoz7ezEH"
      },
      "outputs": [],
      "source": [
        "# We found 35 null values in chlorophyll A. So, we drop the rows with null values\n",
        "X_data = X_data.dropna()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kNSJoIkceS3Z",
        "outputId": "90c94ff9-6960-4c7b-e931-7d28ee6c13e8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "#Checking if we still have any null values\n",
        "X_data.isna().sum().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "RgRdcTXrbXAg"
      },
      "outputs": [],
      "source": [
        "# So, there are no null values in our dataset\n",
        "\n",
        "#Now we need to set the ground truth and input for the model\n",
        "\n",
        "y = X_data[['Chlorophyll-A','SPM700']] # y is the groud truth for the model\n",
        "\n",
        "# X is just the hypstar bands that are going to be input into the model\n",
        "# So, we remove Chlorophyll A and SPM700 columns from X_data to get X\n",
        "X = X_data.drop(['Chlorophyll-A'],axis = 1)\n",
        "X = X.drop(['SPM700'],axis = 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "abO-OTRofYeA",
        "outputId": "6a038dd5-83b7-43b7-8221-717ea99914c2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((2953, 2), (2953, 106))"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "# Printing the shapes of y and X. They should have the same number of rows\n",
        "y.shape,X.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QSY8HVXWoYAz"
      },
      "source": [
        "##Splitting the data into train, test and val sets\n",
        "\n",
        "#### Note\n",
        "\n",
        "- \"random_state = 50\" ensures we get the same values in train, test and val sets everytime. This is important for reproducibility and consistent evaluation of the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "L3E_8Z7JcZGW"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15, random_state=50) # Test dataset = 15% of total dataset\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.15, random_state=50) # Val dataset = 15% of train dataset\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5g9yOXoT-P94"
      },
      "source": [
        "## Data Normalization using Z-Score\n",
        "\n",
        "In this step, we perform Z-score normalization on all datasets. Z-score normalization involves subtracting each feature's mean across the training set and dividing it by its standard deviation in the training set. The objective is to standardize the features, bringing their mean to zero and standard deviation to 1.\n",
        "\n",
        "#### Methodology\n",
        "- **Z-Score Normalization:** Adjusting each feature to have zero mean and unit variance.\n",
        "- So, we calculate mean and std from the train set, perform the normalization and also save the mean and std for later use.\n",
        "\n",
        "#### Rationale\n",
        "Normalization plays a crucial role in enhancing training efficiency. By standardizing the features, we create a more conducive environment for model convergence and acceleration during the training process.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "afNB5doi5-Xw"
      },
      "outputs": [],
      "source": [
        "# Calculate mean and std values\n",
        "mean = X_train.mean()\n",
        "std = X_train.std()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "5jdJNo121-_R"
      },
      "outputs": [],
      "source": [
        "#Performing normalization on all the sets\n",
        "X_train = (X_train - mean)/std\n",
        "X_val = (X_val - mean)/std\n",
        "X_test = (X_test - mean)/std"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9NAa1E6h3zZv",
        "outputId": "68a72a91-985a-43dd-db2a-da5a649a82b0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "400.24    1.165916e-17\n",
              "400.71   -1.557331e-16\n",
              "401.18    6.412540e-17\n",
              "401.65   -5.829582e-17\n",
              "402.13    1.557331e-16\n",
              "              ...     \n",
              "448.08    2.581672e-17\n",
              "448.55   -2.306849e-16\n",
              "449.03    5.579743e-17\n",
              "449.51   -1.415756e-17\n",
              "449.98   -9.160771e-18\n",
              "Length: 106, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "#Checking mean of trainset It should be close to 0\n",
        "X_train.mean()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2M3eIET45-No",
        "outputId": "617a48c5-b3af-4d0f-e306-5c37c800ff7d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "400.24    1.0\n",
              "400.71    1.0\n",
              "401.18    1.0\n",
              "401.65    1.0\n",
              "402.13    1.0\n",
              "         ... \n",
              "448.08    1.0\n",
              "448.55    1.0\n",
              "449.03    1.0\n",
              "449.51    1.0\n",
              "449.98    1.0\n",
              "Length: 106, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "#Checking std of trainset. It should be close to 1\n",
        "X_train.std()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DL2QZULJqm__"
      },
      "source": [
        "# Hyperspectral Image Analysis Model for SPM700 and Chlorophyll A Prediction\n",
        "\n",
        "The model architecture is structured with parallel heads, each dedicated to predicting one of the parameters i.e. chlorophyll A and SPM.\n",
        "\n",
        "## Model Architecture Overview\n",
        "\n",
        "The model employs a 1D convolutional neural network (CNN) to extract intricate patterns and features from the input reflectance bands of the hyperspectral imagery. Both heads use an encoder-like architecture to compress the input progressively into the desired metric. The architecture consists of the following key components:\n",
        "\n",
        "### Parallel Head for Chlorophyll A Prediction (ch1)\n",
        "\n",
        "- **Input Layer:**\n",
        "  - Shape: (Number of Selected Reflectance Bands, 1)\n",
        "  - 1D convolutional layers require an additional dimension.\n",
        "\n",
        "- **Convolutional Layers (ch1):**\n",
        "  - Two sets of convolutional layers with 256 filters and two sets with 128 filters, each followed by leaky ReLU activation.\n",
        "  - These layers capture hierarchical features in the input reflectance bands.\n",
        "\n",
        "- **Flatten Layer (ch1):**\n",
        "  - Converts the output of the convolutional layers into a flat vector.\n",
        "\n",
        "- **Dense Layer (temp_ch1):**\n",
        "  - A fully connected layer with 10 units and leaky ReLU activation, further processing the flattened features.\n",
        "\n",
        "- **Output Layer (ch1):**\n",
        "  - A dense layer with a single unit and softplus activation, producing the final prediction for Chlorophyll A.\n",
        "\n",
        "### Parallel Head for SPM700 Prediction (spm)\n",
        "\n",
        "- **Convolutional Layers (spm):**\n",
        "  - One set with 256 filters, followed by one set with 128 filters, and a final set with 64 filters.\n",
        "  - Similar to the ch1 head, these layers capture hierarchical features for SPM700 prediction.\n",
        "\n",
        "- **Flatten Layer (spm):**\n",
        "  - Converts the output of the convolutional layers into a flat vector.\n",
        "\n",
        "- **Dense Layer (temp_spm):**\n",
        "  - A fully connected layer with 5 units and leaky ReLU activation, further processing the flattened features.\n",
        "\n",
        "- **Output Layer (spm):**\n",
        "  - A dense layer with a single unit and softplus activation, producing the final prediction for SPM700.\n",
        "\n",
        "## Model Training and Compilation\n",
        "\n",
        "The model is trained using the Adam optimizer, and the loss function is Mean Squared Error (MSE). The model is compiled with a custom loss weight configuration, assigning a higher weight (20 times) to the loss of the SPM700 prediction compared to the Chlorophyll A prediction. This is done because SPM loss is smaller in range compared to Chlorophyll  A loss. So, we don't want one loss to dominate the other.\n",
        "\n",
        "## Model Checkpointing\n",
        "\n",
        "To monitor the training process and save the best model, a ModelCheckpoint callback is employed. The best model is determined based on the validation loss, and it is saved to the specified file path.\n",
        "\n",
        "## Model Summary\n",
        "\n",
        "A summary of the model's architecture, including the number of parameters in each layer, is provided for a comprehensive overview of the model structure.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uo55Hoq0cyUr",
        "outputId": "b5d8d729-14e6-4fff-c286-165171bde672"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)        [(None, 106, 1)]             0         []                            \n",
            "                                                                                                  \n",
            " conv1d (Conv1D)             (None, 104, 256)             1024      ['input_1[0][0]']             \n",
            "                                                                                                  \n",
            " conv1d_4 (Conv1D)           (None, 104, 256)             1024      ['input_1[0][0]']             \n",
            "                                                                                                  \n",
            " conv1d_1 (Conv1D)           (None, 102, 256)             196864    ['conv1d[0][0]']              \n",
            "                                                                                                  \n",
            " conv1d_5 (Conv1D)           (None, 102, 128)             98432     ['conv1d_4[0][0]']            \n",
            "                                                                                                  \n",
            " conv1d_2 (Conv1D)           (None, 100, 128)             98432     ['conv1d_1[0][0]']            \n",
            "                                                                                                  \n",
            " conv1d_6 (Conv1D)           (None, 100, 128)             49280     ['conv1d_5[0][0]']            \n",
            "                                                                                                  \n",
            " conv1d_3 (Conv1D)           (None, 98, 128)              49280     ['conv1d_2[0][0]']            \n",
            "                                                                                                  \n",
            " conv1d_7 (Conv1D)           (None, 98, 64)               24640     ['conv1d_6[0][0]']            \n",
            "                                                                                                  \n",
            " flatten (Flatten)           (None, 12544)                0         ['conv1d_3[0][0]']            \n",
            "                                                                                                  \n",
            " flatten_1 (Flatten)         (None, 6272)                 0         ['conv1d_7[0][0]']            \n",
            "                                                                                                  \n",
            " temp_ch1 (Dense)            (None, 10)                   125450    ['flatten[0][0]']             \n",
            "                                                                                                  \n",
            " temp_spm (Dense)            (None, 5)                    31365     ['flatten_1[0][0]']           \n",
            "                                                                                                  \n",
            " ch1 (Dense)                 (None, 1)                    11        ['temp_ch1[0][0]']            \n",
            "                                                                                                  \n",
            " spm (Dense)                 (None, 1)                    6         ['temp_spm[0][0]']            \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 675808 (2.58 MB)\n",
            "Trainable params: 675808 (2.58 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# Define the input layer for hyperspectral reflectance bands\n",
        "input_layer = Input(shape=(len(selected_columns), 1))  # 1D convolutional layers require an additional dimension\n",
        "\n",
        "# Parallel Head for Chlorophyll A Prediction (ch1)\n",
        "conv_ch1_1 = Conv1D(256, kernel_size=3, activation='leaky_relu')(input_layer)\n",
        "conv_ch1_2 = Conv1D(256, kernel_size=3, activation='leaky_relu')(conv_ch1_1)\n",
        "conv_ch1_3 = Conv1D(128, kernel_size=3, activation='leaky_relu')(conv_ch1_2)\n",
        "conv_ch1_4 = Conv1D(128, kernel_size=3, activation='leaky_relu')(conv_ch1_3)\n",
        "flatten_ch1 = Flatten()(conv_ch1_4)\n",
        "temp_ch1 =  Dense(10, name='temp_ch1', activation='leaky_relu')(flatten_ch1)\n",
        "output1 = Dense(1, name='ch1', activation='softplus')(temp_ch1)  # Output for ch1\n",
        "\n",
        "# Parallel Head for SPM700 Prediction (spm)\n",
        "conv_spm_1 = Conv1D(256, kernel_size=3, activation='leaky_relu')(input_layer)\n",
        "conv_spm_2 = Conv1D(128, kernel_size=3, activation='leaky_relu')(conv_spm_1)\n",
        "conv_spm_3 = Conv1D(128, kernel_size=3, activation='leaky_relu')(conv_spm_2)\n",
        "conv_spm_4 = Conv1D(64, kernel_size=3, activation='leaky_relu')(conv_spm_3)\n",
        "flatten_spm = Flatten()(conv_spm_4)\n",
        "temp_spm =  Dense(5, name='temp_spm', activation='leaky_relu')(flatten_spm)\n",
        "output2 = Dense(1, name='spm', activation='softplus')(temp_spm)  # Output for spm\n",
        "\n",
        "# Combine inputs and outputs into a model\n",
        "model = Model(inputs=input_layer, outputs=[output1, output2])\n",
        "\n",
        "# Configure ModelCheckpoint callback to save the best model during training\n",
        "checkpoint = ModelCheckpoint(filepath='/content/drive/MyDrive/Colab Notebooks/HYPSTAR project/HYPSTARv2/best_model.h5',\n",
        "                             monitor='val_loss',  # Monitoring validation loss\n",
        "                             save_best_only=True,  # Save only the best model\n",
        "                             mode='min',  # 'min' for loss, 'max' for accuracy, 'auto' chooses automatically\n",
        "                             verbose=1)  # Print verbose output\n",
        "\n",
        "# Configure Adam optimizer for model compilation\n",
        "opt = Adam()\n",
        "\n",
        "# Compile the model with the custom loss function\n",
        "model.compile(optimizer=opt, loss='mse', loss_weights=[1, 20])  # Use MSE loss with custom weights\n",
        "\n",
        "# Print model summary (optional)\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "Em6RElGYjWZG"
      },
      "outputs": [],
      "source": [
        "#Just converting y_train DF,y_val DF to numpy,since the model needs it in this format\n",
        "y_train_array = y_train.to_numpy()\n",
        "y_val_array = y_val.to_numpy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NJ3jDdFBsF8y"
      },
      "source": [
        "# Starting the training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tFEoxFCRc1nS",
        "outputId": "274d77ac-dd4b-431c-bb84-158a392c75cd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "34/34 [==============================] - ETA: 0s - loss: 694.7944 - ch1_loss: 629.8965 - spm_loss: 3.2449\n",
            "Epoch 1: val_loss did not improve from 575.27362\n",
            "34/34 [==============================] - 17s 496ms/step - loss: 694.7944 - ch1_loss: 629.8965 - spm_loss: 3.2449 - val_loss: 838.3884 - val_ch1_loss: 745.7893 - val_spm_loss: 4.6300\n",
            "Epoch 2/100\n",
            "34/34 [==============================] - ETA: 0s - loss: 842.5698 - ch1_loss: 775.1526 - spm_loss: 3.3709\n",
            "Epoch 2: val_loss improved from 575.27362 to 570.72693, saving model to /content/drive/MyDrive/Colab Notebooks/HYPSTAR project/HYPSTARv2/best_model.h5\n",
            "34/34 [==============================] - 17s 498ms/step - loss: 842.5698 - ch1_loss: 775.1526 - spm_loss: 3.3709 - val_loss: 570.7269 - val_ch1_loss: 508.8806 - val_spm_loss: 3.0923\n",
            "Epoch 3/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "34/34 [==============================] - ETA: 0s - loss: 741.9354 - ch1_loss: 684.3714 - spm_loss: 2.8782\n",
            "Epoch 3: val_loss improved from 570.72693 to 546.59381, saving model to /content/drive/MyDrive/Colab Notebooks/HYPSTAR project/HYPSTARv2/best_model.h5\n",
            "34/34 [==============================] - 17s 503ms/step - loss: 741.9354 - ch1_loss: 684.3714 - spm_loss: 2.8782 - val_loss: 546.5938 - val_ch1_loss: 484.8025 - val_spm_loss: 3.0896\n",
            "Epoch 4/100\n",
            "34/34 [==============================] - ETA: 0s - loss: 689.7124 - ch1_loss: 634.3860 - spm_loss: 2.7663\n",
            "Epoch 4: val_loss improved from 546.59381 to 514.27692, saving model to /content/drive/MyDrive/Colab Notebooks/HYPSTAR project/HYPSTARv2/best_model.h5\n",
            "34/34 [==============================] - 18s 526ms/step - loss: 689.7124 - ch1_loss: 634.3860 - spm_loss: 2.7663 - val_loss: 514.2769 - val_ch1_loss: 461.0128 - val_spm_loss: 2.6632\n",
            "Epoch 5/100\n",
            "34/34 [==============================] - ETA: 0s - loss: 659.0781 - ch1_loss: 602.4287 - spm_loss: 2.8325\n",
            "Epoch 5: val_loss did not improve from 514.27692\n",
            "34/34 [==============================] - 16s 474ms/step - loss: 659.0781 - ch1_loss: 602.4287 - spm_loss: 2.8325 - val_loss: 562.8791 - val_ch1_loss: 496.6076 - val_spm_loss: 3.3136\n",
            "Epoch 6/100\n",
            "34/34 [==============================] - ETA: 0s - loss: 738.5641 - ch1_loss: 685.7527 - spm_loss: 2.6406\n",
            "Epoch 6: val_loss did not improve from 514.27692\n",
            "34/34 [==============================] - 16s 478ms/step - loss: 738.5641 - ch1_loss: 685.7527 - spm_loss: 2.6406 - val_loss: 529.3018 - val_ch1_loss: 466.6379 - val_spm_loss: 3.1332\n",
            "Epoch 7/100\n",
            "34/34 [==============================] - ETA: 0s - loss: 645.1143 - ch1_loss: 595.4528 - spm_loss: 2.4831\n",
            "Epoch 7: val_loss did not improve from 514.27692\n",
            "34/34 [==============================] - 18s 526ms/step - loss: 645.1143 - ch1_loss: 595.4528 - spm_loss: 2.4831 - val_loss: 517.5356 - val_ch1_loss: 462.5904 - val_spm_loss: 2.7473\n",
            "Epoch 8/100\n",
            "34/34 [==============================] - ETA: 0s - loss: 654.0443 - ch1_loss: 608.0314 - spm_loss: 2.3006\n",
            "Epoch 8: val_loss did not improve from 514.27692\n",
            "34/34 [==============================] - 17s 503ms/step - loss: 654.0443 - ch1_loss: 608.0314 - spm_loss: 2.3006 - val_loss: 547.8569 - val_ch1_loss: 500.9846 - val_spm_loss: 2.3436\n",
            "Epoch 9/100\n",
            "34/34 [==============================] - ETA: 0s - loss: 645.8112 - ch1_loss: 595.8044 - spm_loss: 2.5003\n",
            "Epoch 9: val_loss improved from 514.27692 to 511.87173, saving model to /content/drive/MyDrive/Colab Notebooks/HYPSTAR project/HYPSTARv2/best_model.h5\n",
            "34/34 [==============================] - 16s 478ms/step - loss: 645.8112 - ch1_loss: 595.8044 - spm_loss: 2.5003 - val_loss: 511.8717 - val_ch1_loss: 452.4966 - val_spm_loss: 2.9688\n",
            "Epoch 10/100\n",
            "34/34 [==============================] - ETA: 0s - loss: 595.2356 - ch1_loss: 540.6168 - spm_loss: 2.7309\n",
            "Epoch 10: val_loss improved from 511.87173 to 472.71448, saving model to /content/drive/MyDrive/Colab Notebooks/HYPSTAR project/HYPSTARv2/best_model.h5\n",
            "34/34 [==============================] - 17s 496ms/step - loss: 595.2356 - ch1_loss: 540.6168 - spm_loss: 2.7309 - val_loss: 472.7145 - val_ch1_loss: 424.2694 - val_spm_loss: 2.4223\n",
            "Epoch 11/100\n",
            "34/34 [==============================] - ETA: 0s - loss: 567.1430 - ch1_loss: 518.7935 - spm_loss: 2.4175\n",
            "Epoch 11: val_loss did not improve from 472.71448\n",
            "34/34 [==============================] - 17s 506ms/step - loss: 567.1430 - ch1_loss: 518.7935 - spm_loss: 2.4175 - val_loss: 539.1461 - val_ch1_loss: 486.0421 - val_spm_loss: 2.6552\n",
            "Epoch 12/100\n",
            "34/34 [==============================] - ETA: 0s - loss: 595.4553 - ch1_loss: 548.6638 - spm_loss: 2.3396\n",
            "Epoch 12: val_loss did not improve from 472.71448\n",
            "34/34 [==============================] - 18s 514ms/step - loss: 595.4553 - ch1_loss: 548.6638 - spm_loss: 2.3396 - val_loss: 646.4894 - val_ch1_loss: 585.4831 - val_spm_loss: 3.0503\n",
            "Epoch 13/100\n",
            "34/34 [==============================] - ETA: 0s - loss: 538.8347 - ch1_loss: 493.0637 - spm_loss: 2.2886\n",
            "Epoch 13: val_loss improved from 472.71448 to 434.61108, saving model to /content/drive/MyDrive/Colab Notebooks/HYPSTAR project/HYPSTARv2/best_model.h5\n",
            "34/34 [==============================] - 17s 497ms/step - loss: 538.8347 - ch1_loss: 493.0637 - spm_loss: 2.2886 - val_loss: 434.6111 - val_ch1_loss: 389.1292 - val_spm_loss: 2.2741\n",
            "Epoch 14/100\n",
            "34/34 [==============================] - ETA: 0s - loss: 503.1474 - ch1_loss: 459.9742 - spm_loss: 2.1587\n",
            "Epoch 14: val_loss did not improve from 434.61108\n",
            "34/34 [==============================] - 17s 500ms/step - loss: 503.1474 - ch1_loss: 459.9742 - spm_loss: 2.1587 - val_loss: 444.2793 - val_ch1_loss: 394.3740 - val_spm_loss: 2.4953\n",
            "Epoch 15/100\n",
            "34/34 [==============================] - ETA: 0s - loss: 556.2559 - ch1_loss: 505.1135 - spm_loss: 2.5571\n",
            "Epoch 15: val_loss did not improve from 434.61108\n",
            "34/34 [==============================] - 16s 480ms/step - loss: 556.2559 - ch1_loss: 505.1135 - spm_loss: 2.5571 - val_loss: 542.1296 - val_ch1_loss: 484.4485 - val_spm_loss: 2.8841\n",
            "Epoch 16/100\n",
            "34/34 [==============================] - ETA: 0s - loss: 604.4915 - ch1_loss: 556.0566 - spm_loss: 2.4217\n",
            "Epoch 16: val_loss did not improve from 434.61108\n",
            "34/34 [==============================] - 17s 515ms/step - loss: 604.4915 - ch1_loss: 556.0566 - spm_loss: 2.4217 - val_loss: 476.6661 - val_ch1_loss: 422.4218 - val_spm_loss: 2.7122\n",
            "Epoch 17/100\n",
            "34/34 [==============================] - ETA: 0s - loss: 551.7586 - ch1_loss: 503.9238 - spm_loss: 2.3917\n",
            "Epoch 17: val_loss did not improve from 434.61108\n",
            "34/34 [==============================] - 17s 493ms/step - loss: 551.7586 - ch1_loss: 503.9238 - spm_loss: 2.3917 - val_loss: 444.7714 - val_ch1_loss: 401.1201 - val_spm_loss: 2.1826\n",
            "Epoch 18/100\n",
            "34/34 [==============================] - ETA: 0s - loss: 508.1119 - ch1_loss: 467.9943 - spm_loss: 2.0059\n",
            "Epoch 18: val_loss did not improve from 434.61108\n",
            "34/34 [==============================] - 17s 495ms/step - loss: 508.1119 - ch1_loss: 467.9943 - spm_loss: 2.0059 - val_loss: 440.5759 - val_ch1_loss: 392.4831 - val_spm_loss: 2.4046\n",
            "Epoch 19/100\n",
            "34/34 [==============================] - ETA: 0s - loss: 500.7468 - ch1_loss: 455.9332 - spm_loss: 2.2407\n",
            "Epoch 19: val_loss improved from 434.61108 to 414.01459, saving model to /content/drive/MyDrive/Colab Notebooks/HYPSTAR project/HYPSTARv2/best_model.h5\n",
            "34/34 [==============================] - 16s 478ms/step - loss: 500.7468 - ch1_loss: 455.9332 - spm_loss: 2.2407 - val_loss: 414.0146 - val_ch1_loss: 374.2526 - val_spm_loss: 1.9881\n",
            "Epoch 20/100\n",
            "34/34 [==============================] - ETA: 0s - loss: 494.5202 - ch1_loss: 453.1834 - spm_loss: 2.0668\n",
            "Epoch 20: val_loss did not improve from 414.01459\n",
            "34/34 [==============================] - 17s 517ms/step - loss: 494.5202 - ch1_loss: 453.1834 - spm_loss: 2.0668 - val_loss: 443.8405 - val_ch1_loss: 383.2806 - val_spm_loss: 3.0280\n",
            "Epoch 21/100\n",
            "34/34 [==============================] - ETA: 0s - loss: 508.7410 - ch1_loss: 468.8221 - spm_loss: 1.9959\n",
            "Epoch 21: val_loss improved from 414.01459 to 388.79874, saving model to /content/drive/MyDrive/Colab Notebooks/HYPSTAR project/HYPSTARv2/best_model.h5\n",
            "34/34 [==============================] - 17s 502ms/step - loss: 508.7410 - ch1_loss: 468.8221 - spm_loss: 1.9959 - val_loss: 388.7987 - val_ch1_loss: 346.6071 - val_spm_loss: 2.1096\n",
            "Epoch 22/100\n",
            "34/34 [==============================] - ETA: 0s - loss: 463.9744 - ch1_loss: 424.6669 - spm_loss: 1.9654\n",
            "Epoch 22: val_loss did not improve from 388.79874\n",
            "34/34 [==============================] - 16s 476ms/step - loss: 463.9744 - ch1_loss: 424.6669 - spm_loss: 1.9654 - val_loss: 448.7762 - val_ch1_loss: 408.0632 - val_spm_loss: 2.0356\n",
            "Epoch 23/100\n",
            "34/34 [==============================] - ETA: 0s - loss: 488.4595 - ch1_loss: 446.5641 - spm_loss: 2.0948\n",
            "Epoch 23: val_loss did not improve from 388.79874\n",
            "34/34 [==============================] - 17s 492ms/step - loss: 488.4595 - ch1_loss: 446.5641 - spm_loss: 2.0948 - val_loss: 429.7161 - val_ch1_loss: 383.1509 - val_spm_loss: 2.3283\n",
            "Epoch 24/100\n",
            "34/34 [==============================] - ETA: 0s - loss: 493.1409 - ch1_loss: 446.6492 - spm_loss: 2.3246\n",
            "Epoch 24: val_loss did not improve from 388.79874\n",
            "34/34 [==============================] - 17s 498ms/step - loss: 493.1409 - ch1_loss: 446.6492 - spm_loss: 2.3246 - val_loss: 425.4439 - val_ch1_loss: 378.9870 - val_spm_loss: 2.3228\n",
            "Epoch 25/100\n",
            "34/34 [==============================] - ETA: 0s - loss: 480.7657 - ch1_loss: 436.3067 - spm_loss: 2.2229\n",
            "Epoch 25: val_loss did not improve from 388.79874\n",
            "34/34 [==============================] - 17s 504ms/step - loss: 480.7657 - ch1_loss: 436.3067 - spm_loss: 2.2229 - val_loss: 403.9768 - val_ch1_loss: 341.2696 - val_spm_loss: 3.1354\n",
            "Epoch 26/100\n",
            "34/34 [==============================] - ETA: 0s - loss: 544.1647 - ch1_loss: 501.6273 - spm_loss: 2.1269\n",
            "Epoch 26: val_loss improved from 388.79874 to 385.47324, saving model to /content/drive/MyDrive/Colab Notebooks/HYPSTAR project/HYPSTARv2/best_model.h5\n",
            "34/34 [==============================] - 17s 491ms/step - loss: 544.1647 - ch1_loss: 501.6273 - spm_loss: 2.1269 - val_loss: 385.4732 - val_ch1_loss: 348.5845 - val_spm_loss: 1.8444\n",
            "Epoch 27/100\n",
            "34/34 [==============================] - ETA: 0s - loss: 479.6146 - ch1_loss: 438.8944 - spm_loss: 2.0360\n",
            "Epoch 27: val_loss did not improve from 385.47324\n",
            "34/34 [==============================] - 16s 475ms/step - loss: 479.6146 - ch1_loss: 438.8944 - spm_loss: 2.0360 - val_loss: 440.6902 - val_ch1_loss: 386.9355 - val_spm_loss: 2.6877\n",
            "Epoch 28/100\n",
            "34/34 [==============================] - ETA: 0s - loss: 521.8954 - ch1_loss: 480.3184 - spm_loss: 2.0788\n",
            "Epoch 28: val_loss improved from 385.47324 to 377.87823, saving model to /content/drive/MyDrive/Colab Notebooks/HYPSTAR project/HYPSTARv2/best_model.h5\n",
            "34/34 [==============================] - 17s 500ms/step - loss: 521.8954 - ch1_loss: 480.3184 - spm_loss: 2.0788 - val_loss: 377.8782 - val_ch1_loss: 337.5037 - val_spm_loss: 2.0187\n",
            "Epoch 29/100\n",
            "34/34 [==============================] - ETA: 0s - loss: 457.1089 - ch1_loss: 416.1443 - spm_loss: 2.0482\n",
            "Epoch 29: val_loss did not improve from 377.87823\n",
            "34/34 [==============================] - 17s 510ms/step - loss: 457.1089 - ch1_loss: 416.1443 - spm_loss: 2.0482 - val_loss: 412.2935 - val_ch1_loss: 359.5177 - val_spm_loss: 2.6388\n",
            "Epoch 30/100\n",
            "34/34 [==============================] - ETA: 0s - loss: 440.7872 - ch1_loss: 399.2574 - spm_loss: 2.0765\n",
            "Epoch 30: val_loss did not improve from 377.87823\n",
            "34/34 [==============================] - 16s 478ms/step - loss: 440.7872 - ch1_loss: 399.2574 - spm_loss: 2.0765 - val_loss: 418.0565 - val_ch1_loss: 368.5115 - val_spm_loss: 2.4772\n",
            "Epoch 31/100\n",
            "34/34 [==============================] - ETA: 0s - loss: 455.5628 - ch1_loss: 417.0340 - spm_loss: 1.9264\n",
            "Epoch 31: val_loss did not improve from 377.87823\n",
            "34/34 [==============================] - 17s 492ms/step - loss: 455.5628 - ch1_loss: 417.0340 - spm_loss: 1.9264 - val_loss: 382.5396 - val_ch1_loss: 336.7694 - val_spm_loss: 2.2885\n",
            "Epoch 32/100\n",
            "34/34 [==============================] - ETA: 0s - loss: 467.1799 - ch1_loss: 431.0640 - spm_loss: 1.8058\n",
            "Epoch 32: val_loss did not improve from 377.87823\n",
            "34/34 [==============================] - 17s 498ms/step - loss: 467.1799 - ch1_loss: 431.0640 - spm_loss: 1.8058 - val_loss: 409.3775 - val_ch1_loss: 351.4319 - val_spm_loss: 2.8973\n",
            "Epoch 33/100\n",
            "34/34 [==============================] - ETA: 0s - loss: 450.3025 - ch1_loss: 406.9054 - spm_loss: 2.1699\n",
            "Epoch 33: val_loss improved from 377.87823 to 355.48380, saving model to /content/drive/MyDrive/Colab Notebooks/HYPSTAR project/HYPSTARv2/best_model.h5\n",
            "34/34 [==============================] - 17s 509ms/step - loss: 450.3025 - ch1_loss: 406.9054 - spm_loss: 2.1699 - val_loss: 355.4838 - val_ch1_loss: 304.7847 - val_spm_loss: 2.5350\n",
            "Epoch 34/100\n",
            "34/34 [==============================] - ETA: 0s - loss: 445.7745 - ch1_loss: 408.4395 - spm_loss: 1.8667\n",
            "Epoch 34: val_loss did not improve from 355.48380\n",
            "34/34 [==============================] - 17s 492ms/step - loss: 445.7745 - ch1_loss: 408.4395 - spm_loss: 1.8667 - val_loss: 367.3409 - val_ch1_loss: 328.1810 - val_spm_loss: 1.9580\n",
            "Epoch 35/100\n",
            "34/34 [==============================] - ETA: 0s - loss: 436.0979 - ch1_loss: 395.9118 - spm_loss: 2.0093\n",
            "Epoch 35: val_loss did not improve from 355.48380\n",
            "34/34 [==============================] - 17s 494ms/step - loss: 436.0979 - ch1_loss: 395.9118 - spm_loss: 2.0093 - val_loss: 383.2333 - val_ch1_loss: 326.4230 - val_spm_loss: 2.8405\n",
            "Epoch 36/100\n",
            "34/34 [==============================] - ETA: 0s - loss: 454.4138 - ch1_loss: 413.8787 - spm_loss: 2.0268\n",
            "Epoch 36: val_loss did not improve from 355.48380\n",
            "34/34 [==============================] - 17s 500ms/step - loss: 454.4138 - ch1_loss: 413.8787 - spm_loss: 2.0268 - val_loss: 369.6122 - val_ch1_loss: 324.9133 - val_spm_loss: 2.2349\n",
            "Epoch 37/100\n",
            "34/34 [==============================] - ETA: 0s - loss: 452.1874 - ch1_loss: 416.9443 - spm_loss: 1.7622\n",
            "Epoch 37: val_loss did not improve from 355.48380\n",
            "34/34 [==============================] - 17s 501ms/step - loss: 452.1874 - ch1_loss: 416.9443 - spm_loss: 1.7622 - val_loss: 371.7920 - val_ch1_loss: 318.4821 - val_spm_loss: 2.6655\n",
            "Epoch 38/100\n",
            "34/34 [==============================] - ETA: 0s - loss: 439.1864 - ch1_loss: 401.5152 - spm_loss: 1.8836\n",
            "Epoch 38: val_loss did not improve from 355.48380\n",
            "34/34 [==============================] - 17s 487ms/step - loss: 439.1864 - ch1_loss: 401.5152 - spm_loss: 1.8836 - val_loss: 431.2247 - val_ch1_loss: 390.0875 - val_spm_loss: 2.0569\n",
            "Epoch 39/100\n",
            "34/34 [==============================] - ETA: 0s - loss: 448.6746 - ch1_loss: 412.2657 - spm_loss: 1.8205\n",
            "Epoch 39: val_loss did not improve from 355.48380\n",
            "34/34 [==============================] - 17s 496ms/step - loss: 448.6746 - ch1_loss: 412.2657 - spm_loss: 1.8205 - val_loss: 382.2495 - val_ch1_loss: 345.4585 - val_spm_loss: 1.8396\n",
            "Epoch 40/100\n",
            "34/34 [==============================] - ETA: 0s - loss: 447.3450 - ch1_loss: 409.6570 - spm_loss: 1.8844\n",
            "Epoch 40: val_loss did not improve from 355.48380\n",
            "34/34 [==============================] - 17s 494ms/step - loss: 447.3450 - ch1_loss: 409.6570 - spm_loss: 1.8844 - val_loss: 398.2197 - val_ch1_loss: 352.4504 - val_spm_loss: 2.2885\n",
            "Epoch 41/100\n",
            "34/34 [==============================] - ETA: 0s - loss: 444.4867 - ch1_loss: 405.2309 - spm_loss: 1.9628\n",
            "Epoch 41: val_loss did not improve from 355.48380\n",
            "34/34 [==============================] - 17s 509ms/step - loss: 444.4867 - ch1_loss: 405.2309 - spm_loss: 1.9628 - val_loss: 386.2411 - val_ch1_loss: 347.1600 - val_spm_loss: 1.9541\n",
            "Epoch 42/100\n",
            "34/34 [==============================] - ETA: 0s - loss: 418.4511 - ch1_loss: 383.0018 - spm_loss: 1.7725\n",
            "Epoch 42: val_loss improved from 355.48380 to 350.01468, saving model to /content/drive/MyDrive/Colab Notebooks/HYPSTAR project/HYPSTARv2/best_model.h5\n",
            "34/34 [==============================] - 16s 479ms/step - loss: 418.4511 - ch1_loss: 383.0018 - spm_loss: 1.7725 - val_loss: 350.0147 - val_ch1_loss: 309.8245 - val_spm_loss: 2.0095\n",
            "Epoch 43/100\n",
            "34/34 [==============================] - ETA: 0s - loss: 423.6718 - ch1_loss: 383.3699 - spm_loss: 2.0151\n",
            "Epoch 43: val_loss did not improve from 350.01468\n",
            "34/34 [==============================] - 17s 488ms/step - loss: 423.6718 - ch1_loss: 383.3699 - spm_loss: 2.0151 - val_loss: 427.4346 - val_ch1_loss: 379.5304 - val_spm_loss: 2.3952\n",
            "Epoch 44/100\n",
            "34/34 [==============================] - ETA: 0s - loss: 466.6247 - ch1_loss: 426.4877 - spm_loss: 2.0069\n",
            "Epoch 44: val_loss did not improve from 350.01468\n",
            "34/34 [==============================] - 17s 488ms/step - loss: 466.6247 - ch1_loss: 426.4877 - spm_loss: 2.0069 - val_loss: 447.9118 - val_ch1_loss: 405.7861 - val_spm_loss: 2.1063\n",
            "Epoch 45/100\n",
            "34/34 [==============================] - ETA: 0s - loss: 463.3542 - ch1_loss: 418.2567 - spm_loss: 2.2549\n",
            "Epoch 45: val_loss did not improve from 350.01468\n",
            "34/34 [==============================] - 17s 493ms/step - loss: 463.3542 - ch1_loss: 418.2567 - spm_loss: 2.2549 - val_loss: 353.7555 - val_ch1_loss: 313.7518 - val_spm_loss: 2.0002\n",
            "Epoch 46/100\n",
            "34/34 [==============================] - ETA: 0s - loss: 475.3277 - ch1_loss: 437.3511 - spm_loss: 1.8988\n",
            "Epoch 46: val_loss did not improve from 350.01468\n",
            "34/34 [==============================] - 17s 495ms/step - loss: 475.3277 - ch1_loss: 437.3511 - spm_loss: 1.8988 - val_loss: 405.7244 - val_ch1_loss: 362.3146 - val_spm_loss: 2.1705\n",
            "Epoch 47/100\n",
            "34/34 [==============================] - ETA: 0s - loss: 455.2762 - ch1_loss: 416.3382 - spm_loss: 1.9469\n",
            "Epoch 47: val_loss did not improve from 350.01468\n",
            "34/34 [==============================] - 16s 473ms/step - loss: 455.2762 - ch1_loss: 416.3382 - spm_loss: 1.9469 - val_loss: 403.4334 - val_ch1_loss: 363.1212 - val_spm_loss: 2.0156\n",
            "Epoch 48/100\n",
            "34/34 [==============================] - ETA: 0s - loss: 459.7780 - ch1_loss: 418.9891 - spm_loss: 2.0394\n",
            "Epoch 48: val_loss did not improve from 350.01468\n",
            "34/34 [==============================] - 16s 479ms/step - loss: 459.7780 - ch1_loss: 418.9891 - spm_loss: 2.0394 - val_loss: 371.6357 - val_ch1_loss: 321.9342 - val_spm_loss: 2.4851\n",
            "Epoch 49/100\n",
            "34/34 [==============================] - ETA: 0s - loss: 437.1250 - ch1_loss: 399.5131 - spm_loss: 1.8806\n",
            "Epoch 49: val_loss did not improve from 350.01468\n",
            "34/34 [==============================] - 17s 507ms/step - loss: 437.1250 - ch1_loss: 399.5131 - spm_loss: 1.8806 - val_loss: 352.6132 - val_ch1_loss: 308.4919 - val_spm_loss: 2.2061\n",
            "Epoch 50/100\n",
            "34/34 [==============================] - ETA: 0s - loss: 405.2553 - ch1_loss: 366.7219 - spm_loss: 1.9267\n",
            "Epoch 50: val_loss improved from 350.01468 to 344.85077, saving model to /content/drive/MyDrive/Colab Notebooks/HYPSTAR project/HYPSTARv2/best_model.h5\n",
            "34/34 [==============================] - 17s 500ms/step - loss: 405.2553 - ch1_loss: 366.7219 - spm_loss: 1.9267 - val_loss: 344.8508 - val_ch1_loss: 302.0223 - val_spm_loss: 2.1414\n",
            "Epoch 51/100\n",
            "34/34 [==============================] - ETA: 0s - loss: 456.4720 - ch1_loss: 419.3377 - spm_loss: 1.8567\n",
            "Epoch 51: val_loss improved from 344.85077 to 331.43082, saving model to /content/drive/MyDrive/Colab Notebooks/HYPSTAR project/HYPSTARv2/best_model.h5\n",
            "34/34 [==============================] - 17s 492ms/step - loss: 456.4720 - ch1_loss: 419.3377 - spm_loss: 1.8567 - val_loss: 331.4308 - val_ch1_loss: 296.6883 - val_spm_loss: 1.7371\n",
            "Epoch 52/100\n",
            "34/34 [==============================] - ETA: 0s - loss: 422.8748 - ch1_loss: 378.4688 - spm_loss: 2.2203\n",
            "Epoch 52: val_loss did not improve from 331.43082\n",
            "34/34 [==============================] - 17s 490ms/step - loss: 422.8748 - ch1_loss: 378.4688 - spm_loss: 2.2203 - val_loss: 368.9621 - val_ch1_loss: 320.3662 - val_spm_loss: 2.4298\n",
            "Epoch 53/100\n",
            "34/34 [==============================] - ETA: 0s - loss: 413.5045 - ch1_loss: 376.9758 - spm_loss: 1.8264\n",
            "Epoch 53: val_loss did not improve from 331.43082\n",
            "34/34 [==============================] - 17s 507ms/step - loss: 413.5045 - ch1_loss: 376.9758 - spm_loss: 1.8264 - val_loss: 384.8139 - val_ch1_loss: 322.7212 - val_spm_loss: 3.1046\n",
            "Epoch 54/100\n",
            "34/34 [==============================] - ETA: 0s - loss: 445.8196 - ch1_loss: 409.9353 - spm_loss: 1.7942\n",
            "Epoch 54: val_loss did not improve from 331.43082\n",
            "34/34 [==============================] - 17s 480ms/step - loss: 445.8196 - ch1_loss: 409.9353 - spm_loss: 1.7942 - val_loss: 454.0991 - val_ch1_loss: 417.1886 - val_spm_loss: 1.8455\n",
            "Epoch 55/100\n",
            "34/34 [==============================] - ETA: 0s - loss: 469.4104 - ch1_loss: 435.2224 - spm_loss: 1.7094\n",
            "Epoch 55: val_loss did not improve from 331.43082\n",
            "34/34 [==============================] - 17s 492ms/step - loss: 469.4104 - ch1_loss: 435.2224 - spm_loss: 1.7094 - val_loss: 368.9026 - val_ch1_loss: 328.5098 - val_spm_loss: 2.0196\n",
            "Epoch 56/100\n",
            "34/34 [==============================] - ETA: 0s - loss: 401.0091 - ch1_loss: 367.1111 - spm_loss: 1.6949\n",
            "Epoch 56: val_loss did not improve from 331.43082\n",
            "34/34 [==============================] - 17s 496ms/step - loss: 401.0091 - ch1_loss: 367.1111 - spm_loss: 1.6949 - val_loss: 338.3000 - val_ch1_loss: 293.6476 - val_spm_loss: 2.2326\n",
            "Epoch 57/100\n",
            "34/34 [==============================] - ETA: 0s - loss: 412.7926 - ch1_loss: 371.0866 - spm_loss: 2.0853\n",
            "Epoch 57: val_loss improved from 331.43082 to 327.30054, saving model to /content/drive/MyDrive/Colab Notebooks/HYPSTAR project/HYPSTARv2/best_model.h5\n",
            "34/34 [==============================] - 17s 500ms/step - loss: 412.7926 - ch1_loss: 371.0866 - spm_loss: 2.0853 - val_loss: 327.3005 - val_ch1_loss: 288.7578 - val_spm_loss: 1.9271\n",
            "Epoch 58/100\n",
            "34/34 [==============================] - ETA: 0s - loss: 401.2792 - ch1_loss: 368.1339 - spm_loss: 1.6573\n",
            "Epoch 58: val_loss did not improve from 327.30054\n",
            "34/34 [==============================] - 17s 503ms/step - loss: 401.2792 - ch1_loss: 368.1339 - spm_loss: 1.6573 - val_loss: 339.6661 - val_ch1_loss: 303.7849 - val_spm_loss: 1.7941\n",
            "Epoch 59/100\n",
            "34/34 [==============================] - ETA: 0s - loss: 406.7328 - ch1_loss: 371.8322 - spm_loss: 1.7450\n",
            "Epoch 59: val_loss did not improve from 327.30054\n",
            "34/34 [==============================] - 16s 472ms/step - loss: 406.7328 - ch1_loss: 371.8322 - spm_loss: 1.7450 - val_loss: 350.6149 - val_ch1_loss: 314.8838 - val_spm_loss: 1.7866\n",
            "Epoch 60/100\n",
            "34/34 [==============================] - ETA: 0s - loss: 423.4042 - ch1_loss: 390.9197 - spm_loss: 1.6242\n",
            "Epoch 60: val_loss did not improve from 327.30054\n",
            "34/34 [==============================] - 17s 491ms/step - loss: 423.4042 - ch1_loss: 390.9197 - spm_loss: 1.6242 - val_loss: 370.6692 - val_ch1_loss: 325.1714 - val_spm_loss: 2.2749\n",
            "Epoch 61/100\n",
            "34/34 [==============================] - ETA: 0s - loss: 449.6515 - ch1_loss: 414.5202 - spm_loss: 1.7566\n",
            "Epoch 61: val_loss did not improve from 327.30054\n",
            "34/34 [==============================] - 16s 471ms/step - loss: 449.6515 - ch1_loss: 414.5202 - spm_loss: 1.7566 - val_loss: 346.3079 - val_ch1_loss: 298.9865 - val_spm_loss: 2.3661\n",
            "Epoch 62/100\n",
            "34/34 [==============================] - ETA: 0s - loss: 415.7325 - ch1_loss: 379.1025 - spm_loss: 1.8315\n",
            "Epoch 62: val_loss did not improve from 327.30054\n",
            "34/34 [==============================] - 18s 514ms/step - loss: 415.7325 - ch1_loss: 379.1025 - spm_loss: 1.8315 - val_loss: 403.5743 - val_ch1_loss: 362.1343 - val_spm_loss: 2.0720\n",
            "Epoch 63/100\n",
            "34/34 [==============================] - ETA: 0s - loss: 392.2096 - ch1_loss: 358.7599 - spm_loss: 1.6725\n",
            "Epoch 63: val_loss did not improve from 327.30054\n",
            "34/34 [==============================] - 16s 465ms/step - loss: 392.2096 - ch1_loss: 358.7599 - spm_loss: 1.6725 - val_loss: 379.7415 - val_ch1_loss: 338.6449 - val_spm_loss: 2.0548\n",
            "Epoch 64/100\n",
            "34/34 [==============================] - ETA: 0s - loss: 447.9581 - ch1_loss: 416.3764 - spm_loss: 1.5791\n",
            "Epoch 64: val_loss did not improve from 327.30054\n",
            "34/34 [==============================] - 16s 479ms/step - loss: 447.9581 - ch1_loss: 416.3764 - spm_loss: 1.5791 - val_loss: 386.3420 - val_ch1_loss: 340.3349 - val_spm_loss: 2.3004\n",
            "Epoch 65/100\n",
            "34/34 [==============================] - ETA: 0s - loss: 408.1647 - ch1_loss: 377.2085 - spm_loss: 1.5478\n",
            "Epoch 65: val_loss improved from 327.30054 to 320.24637, saving model to /content/drive/MyDrive/Colab Notebooks/HYPSTAR project/HYPSTARv2/best_model.h5\n",
            "34/34 [==============================] - 17s 499ms/step - loss: 408.1647 - ch1_loss: 377.2085 - spm_loss: 1.5478 - val_loss: 320.2464 - val_ch1_loss: 283.7546 - val_spm_loss: 1.8246\n",
            "Epoch 66/100\n",
            "34/34 [==============================] - ETA: 0s - loss: 396.5343 - ch1_loss: 367.0172 - spm_loss: 1.4759\n",
            "Epoch 66: val_loss did not improve from 320.24637\n",
            "34/34 [==============================] - 17s 501ms/step - loss: 396.5343 - ch1_loss: 367.0172 - spm_loss: 1.4759 - val_loss: 336.9572 - val_ch1_loss: 299.3450 - val_spm_loss: 1.8806\n",
            "Epoch 67/100\n",
            "34/34 [==============================] - ETA: 0s - loss: 442.7496 - ch1_loss: 412.1161 - spm_loss: 1.5317\n",
            "Epoch 67: val_loss did not improve from 320.24637\n",
            "34/34 [==============================] - 17s 505ms/step - loss: 442.7496 - ch1_loss: 412.1161 - spm_loss: 1.5317 - val_loss: 435.7637 - val_ch1_loss: 390.2699 - val_spm_loss: 2.2747\n",
            "Epoch 68/100\n",
            "34/34 [==============================] - ETA: 0s - loss: 392.0609 - ch1_loss: 360.2707 - spm_loss: 1.5895\n",
            "Epoch 68: val_loss improved from 320.24637 to 315.14105, saving model to /content/drive/MyDrive/Colab Notebooks/HYPSTAR project/HYPSTARv2/best_model.h5\n",
            "34/34 [==============================] - 16s 481ms/step - loss: 392.0609 - ch1_loss: 360.2707 - spm_loss: 1.5895 - val_loss: 315.1411 - val_ch1_loss: 276.5750 - val_spm_loss: 1.9283\n",
            "Epoch 69/100\n",
            "34/34 [==============================] - ETA: 0s - loss: 413.7664 - ch1_loss: 381.1524 - spm_loss: 1.6307\n",
            "Epoch 69: val_loss did not improve from 315.14105\n",
            "34/34 [==============================] - 17s 494ms/step - loss: 413.7664 - ch1_loss: 381.1524 - spm_loss: 1.6307 - val_loss: 384.5814 - val_ch1_loss: 333.6465 - val_spm_loss: 2.5467\n",
            "Epoch 70/100\n",
            "34/34 [==============================] - ETA: 0s - loss: 376.9212 - ch1_loss: 344.7937 - spm_loss: 1.6064\n",
            "Epoch 70: val_loss did not improve from 315.14105\n",
            "34/34 [==============================] - 17s 496ms/step - loss: 376.9212 - ch1_loss: 344.7937 - spm_loss: 1.6064 - val_loss: 321.5783 - val_ch1_loss: 282.1977 - val_spm_loss: 1.9690\n",
            "Epoch 71/100\n",
            "34/34 [==============================] - ETA: 0s - loss: 368.9518 - ch1_loss: 338.4323 - spm_loss: 1.5260\n",
            "Epoch 71: val_loss did not improve from 315.14105\n",
            "34/34 [==============================] - 17s 509ms/step - loss: 368.9518 - ch1_loss: 338.4323 - spm_loss: 1.5260 - val_loss: 335.7805 - val_ch1_loss: 300.2135 - val_spm_loss: 1.7784\n",
            "Epoch 72/100\n",
            "34/34 [==============================] - ETA: 0s - loss: 419.0219 - ch1_loss: 389.0292 - spm_loss: 1.4996\n",
            "Epoch 72: val_loss did not improve from 315.14105\n",
            "34/34 [==============================] - 17s 490ms/step - loss: 419.0219 - ch1_loss: 389.0292 - spm_loss: 1.4996 - val_loss: 419.3793 - val_ch1_loss: 383.6256 - val_spm_loss: 1.7877\n",
            "Epoch 73/100\n",
            "34/34 [==============================] - ETA: 0s - loss: 418.6516 - ch1_loss: 387.4388 - spm_loss: 1.5606\n",
            "Epoch 73: val_loss did not improve from 315.14105\n",
            "34/34 [==============================] - 17s 493ms/step - loss: 418.6516 - ch1_loss: 387.4388 - spm_loss: 1.5606 - val_loss: 350.0945 - val_ch1_loss: 307.7610 - val_spm_loss: 2.1167\n",
            "Epoch 74/100\n",
            "34/34 [==============================] - ETA: 0s - loss: 385.7996 - ch1_loss: 356.2988 - spm_loss: 1.4750\n",
            "Epoch 74: val_loss did not improve from 315.14105\n",
            "34/34 [==============================] - 17s 500ms/step - loss: 385.7996 - ch1_loss: 356.2988 - spm_loss: 1.4750 - val_loss: 333.1313 - val_ch1_loss: 292.8182 - val_spm_loss: 2.0157\n",
            "Epoch 75/100\n",
            "34/34 [==============================] - ETA: 0s - loss: 449.8967 - ch1_loss: 414.2964 - spm_loss: 1.7800\n",
            "Epoch 75: val_loss did not improve from 315.14105\n",
            "34/34 [==============================] - 18s 516ms/step - loss: 449.8967 - ch1_loss: 414.2964 - spm_loss: 1.7800 - val_loss: 343.2735 - val_ch1_loss: 298.6772 - val_spm_loss: 2.2298\n",
            "Epoch 76/100\n",
            "34/34 [==============================] - ETA: 0s - loss: 421.6086 - ch1_loss: 390.9380 - spm_loss: 1.5335\n",
            "Epoch 76: val_loss did not improve from 315.14105\n",
            "34/34 [==============================] - 17s 497ms/step - loss: 421.6086 - ch1_loss: 390.9380 - spm_loss: 1.5335 - val_loss: 353.8233 - val_ch1_loss: 317.8256 - val_spm_loss: 1.7999\n",
            "Epoch 77/100\n",
            "34/34 [==============================] - ETA: 0s - loss: 375.6216 - ch1_loss: 346.5928 - spm_loss: 1.4514\n",
            "Epoch 77: val_loss did not improve from 315.14105\n",
            "34/34 [==============================] - 17s 495ms/step - loss: 375.6216 - ch1_loss: 346.5928 - spm_loss: 1.4514 - val_loss: 337.4790 - val_ch1_loss: 293.0956 - val_spm_loss: 2.2192\n",
            "Epoch 78/100\n",
            "34/34 [==============================] - ETA: 0s - loss: 379.2149 - ch1_loss: 347.8591 - spm_loss: 1.5678\n",
            "Epoch 78: val_loss improved from 315.14105 to 309.16803, saving model to /content/drive/MyDrive/Colab Notebooks/HYPSTAR project/HYPSTARv2/best_model.h5\n",
            "34/34 [==============================] - 17s 492ms/step - loss: 379.2149 - ch1_loss: 347.8591 - spm_loss: 1.5678 - val_loss: 309.1680 - val_ch1_loss: 268.7456 - val_spm_loss: 2.0211\n",
            "Epoch 79/100\n",
            "34/34 [==============================] - ETA: 0s - loss: 361.1720 - ch1_loss: 329.9893 - spm_loss: 1.5591\n",
            "Epoch 79: val_loss did not improve from 309.16803\n",
            "34/34 [==============================] - 17s 489ms/step - loss: 361.1720 - ch1_loss: 329.9893 - spm_loss: 1.5591 - val_loss: 411.3495 - val_ch1_loss: 376.1227 - val_spm_loss: 1.7613\n",
            "Epoch 80/100\n",
            "34/34 [==============================] - ETA: 0s - loss: 398.8365 - ch1_loss: 367.3098 - spm_loss: 1.5763\n",
            "Epoch 80: val_loss did not improve from 309.16803\n",
            "34/34 [==============================] - 17s 494ms/step - loss: 398.8365 - ch1_loss: 367.3098 - spm_loss: 1.5763 - val_loss: 331.9576 - val_ch1_loss: 283.8756 - val_spm_loss: 2.4041\n",
            "Epoch 81/100\n",
            "34/34 [==============================] - ETA: 0s - loss: 379.1863 - ch1_loss: 350.9113 - spm_loss: 1.4137\n",
            "Epoch 81: val_loss did not improve from 309.16803\n",
            "34/34 [==============================] - 16s 478ms/step - loss: 379.1863 - ch1_loss: 350.9113 - spm_loss: 1.4137 - val_loss: 364.5565 - val_ch1_loss: 328.5431 - val_spm_loss: 1.8007\n",
            "Epoch 82/100\n",
            "34/34 [==============================] - ETA: 0s - loss: 380.8810 - ch1_loss: 348.9322 - spm_loss: 1.5974\n",
            "Epoch 82: val_loss did not improve from 309.16803\n",
            "34/34 [==============================] - 17s 497ms/step - loss: 380.8810 - ch1_loss: 348.9322 - spm_loss: 1.5974 - val_loss: 348.7666 - val_ch1_loss: 305.9473 - val_spm_loss: 2.1410\n",
            "Epoch 83/100\n",
            "34/34 [==============================] - ETA: 0s - loss: 376.2220 - ch1_loss: 348.8450 - spm_loss: 1.3688\n",
            "Epoch 83: val_loss did not improve from 309.16803\n",
            "34/34 [==============================] - 18s 521ms/step - loss: 376.2220 - ch1_loss: 348.8450 - spm_loss: 1.3688 - val_loss: 311.6281 - val_ch1_loss: 270.6227 - val_spm_loss: 2.0503\n",
            "Epoch 84/100\n",
            "34/34 [==============================] - ETA: 0s - loss: 356.2390 - ch1_loss: 329.2467 - spm_loss: 1.3496\n",
            "Epoch 84: val_loss did not improve from 309.16803\n",
            "34/34 [==============================] - 17s 494ms/step - loss: 356.2390 - ch1_loss: 329.2467 - spm_loss: 1.3496 - val_loss: 328.3922 - val_ch1_loss: 286.7686 - val_spm_loss: 2.0812\n",
            "Epoch 85/100\n",
            "34/34 [==============================] - ETA: 0s - loss: 348.5139 - ch1_loss: 322.5300 - spm_loss: 1.2992\n",
            "Epoch 85: val_loss improved from 309.16803 to 294.08160, saving model to /content/drive/MyDrive/Colab Notebooks/HYPSTAR project/HYPSTARv2/best_model.h5\n",
            "34/34 [==============================] - 17s 495ms/step - loss: 348.5139 - ch1_loss: 322.5300 - spm_loss: 1.2992 - val_loss: 294.0816 - val_ch1_loss: 254.0292 - val_spm_loss: 2.0026\n",
            "Epoch 86/100\n",
            "34/34 [==============================] - ETA: 0s - loss: 341.9600 - ch1_loss: 315.2357 - spm_loss: 1.3362\n",
            "Epoch 86: val_loss improved from 294.08160 to 278.05286, saving model to /content/drive/MyDrive/Colab Notebooks/HYPSTAR project/HYPSTARv2/best_model.h5\n",
            "34/34 [==============================] - 17s 501ms/step - loss: 341.9600 - ch1_loss: 315.2357 - spm_loss: 1.3362 - val_loss: 278.0529 - val_ch1_loss: 235.7299 - val_spm_loss: 2.1161\n",
            "Epoch 87/100\n",
            "34/34 [==============================] - ETA: 0s - loss: 354.9229 - ch1_loss: 328.6298 - spm_loss: 1.3147\n",
            "Epoch 87: val_loss did not improve from 278.05286\n",
            "34/34 [==============================] - 18s 517ms/step - loss: 354.9229 - ch1_loss: 328.6298 - spm_loss: 1.3147 - val_loss: 341.0900 - val_ch1_loss: 293.0294 - val_spm_loss: 2.4030\n",
            "Epoch 88/100\n",
            "34/34 [==============================] - ETA: 0s - loss: 347.7018 - ch1_loss: 318.7180 - spm_loss: 1.4492\n",
            "Epoch 88: val_loss did not improve from 278.05286\n",
            "34/34 [==============================] - 16s 486ms/step - loss: 347.7018 - ch1_loss: 318.7180 - spm_loss: 1.4492 - val_loss: 377.8073 - val_ch1_loss: 328.2771 - val_spm_loss: 2.4765\n",
            "Epoch 89/100\n",
            "34/34 [==============================] - ETA: 0s - loss: 341.9329 - ch1_loss: 309.6093 - spm_loss: 1.6162\n",
            "Epoch 89: val_loss did not improve from 278.05286\n",
            "34/34 [==============================] - 17s 503ms/step - loss: 341.9329 - ch1_loss: 309.6093 - spm_loss: 1.6162 - val_loss: 315.8631 - val_ch1_loss: 270.6101 - val_spm_loss: 2.2626\n",
            "Epoch 90/100\n",
            "34/34 [==============================] - ETA: 0s - loss: 349.7456 - ch1_loss: 323.9110 - spm_loss: 1.2917\n",
            "Epoch 90: val_loss did not improve from 278.05286\n",
            "34/34 [==============================] - 17s 498ms/step - loss: 349.7456 - ch1_loss: 323.9110 - spm_loss: 1.2917 - val_loss: 362.6057 - val_ch1_loss: 319.0852 - val_spm_loss: 2.1760\n",
            "Epoch 91/100\n",
            "34/34 [==============================] - ETA: 0s - loss: 350.4745 - ch1_loss: 324.8187 - spm_loss: 1.2828\n",
            "Epoch 91: val_loss did not improve from 278.05286\n",
            "34/34 [==============================] - 17s 496ms/step - loss: 350.4745 - ch1_loss: 324.8187 - spm_loss: 1.2828 - val_loss: 297.2087 - val_ch1_loss: 253.4337 - val_spm_loss: 2.1887\n",
            "Epoch 92/100\n",
            "34/34 [==============================] - ETA: 0s - loss: 351.3018 - ch1_loss: 320.5679 - spm_loss: 1.5367\n",
            "Epoch 92: val_loss did not improve from 278.05286\n",
            "34/34 [==============================] - 17s 496ms/step - loss: 351.3018 - ch1_loss: 320.5679 - spm_loss: 1.5367 - val_loss: 351.7935 - val_ch1_loss: 305.7886 - val_spm_loss: 2.3002\n",
            "Epoch 93/100\n",
            "34/34 [==============================] - ETA: 0s - loss: 400.4330 - ch1_loss: 372.3923 - spm_loss: 1.4020\n",
            "Epoch 93: val_loss did not improve from 278.05286\n",
            "34/34 [==============================] - 17s 496ms/step - loss: 400.4330 - ch1_loss: 372.3923 - spm_loss: 1.4020 - val_loss: 371.3812 - val_ch1_loss: 330.6472 - val_spm_loss: 2.0367\n",
            "Epoch 94/100\n",
            "34/34 [==============================] - ETA: 0s - loss: 359.9754 - ch1_loss: 336.6768 - spm_loss: 1.1649\n",
            "Epoch 94: val_loss did not improve from 278.05286\n",
            "34/34 [==============================] - 16s 477ms/step - loss: 359.9754 - ch1_loss: 336.6768 - spm_loss: 1.1649 - val_loss: 346.1048 - val_ch1_loss: 288.7957 - val_spm_loss: 2.8655\n",
            "Epoch 95/100\n",
            "34/34 [==============================] - ETA: 0s - loss: 352.8642 - ch1_loss: 327.8112 - spm_loss: 1.2526\n",
            "Epoch 95: val_loss did not improve from 278.05286\n",
            "34/34 [==============================] - 17s 508ms/step - loss: 352.8642 - ch1_loss: 327.8112 - spm_loss: 1.2526 - val_loss: 357.9166 - val_ch1_loss: 307.4626 - val_spm_loss: 2.5227\n",
            "Epoch 96/100\n",
            "34/34 [==============================] - ETA: 0s - loss: 339.5078 - ch1_loss: 315.2262 - spm_loss: 1.2141\n",
            "Epoch 96: val_loss did not improve from 278.05286\n",
            "34/34 [==============================] - 16s 476ms/step - loss: 339.5078 - ch1_loss: 315.2262 - spm_loss: 1.2141 - val_loss: 290.7739 - val_ch1_loss: 248.2981 - val_spm_loss: 2.1238\n",
            "Epoch 97/100\n",
            "34/34 [==============================] - ETA: 0s - loss: 322.5906 - ch1_loss: 296.3274 - spm_loss: 1.3132\n",
            "Epoch 97: val_loss did not improve from 278.05286\n",
            "34/34 [==============================] - 16s 473ms/step - loss: 322.5906 - ch1_loss: 296.3274 - spm_loss: 1.3132 - val_loss: 342.2932 - val_ch1_loss: 282.3605 - val_spm_loss: 2.9966\n",
            "Epoch 98/100\n",
            "34/34 [==============================] - ETA: 0s - loss: 315.7702 - ch1_loss: 287.7313 - spm_loss: 1.4019\n",
            "Epoch 98: val_loss did not improve from 278.05286\n",
            "34/34 [==============================] - 17s 487ms/step - loss: 315.7702 - ch1_loss: 287.7313 - spm_loss: 1.4019 - val_loss: 388.3316 - val_ch1_loss: 330.1323 - val_spm_loss: 2.9100\n",
            "Epoch 99/100\n",
            "34/34 [==============================] - ETA: 0s - loss: 316.0105 - ch1_loss: 291.4371 - spm_loss: 1.2287\n",
            "Epoch 99: val_loss did not improve from 278.05286\n",
            "34/34 [==============================] - 17s 502ms/step - loss: 316.0105 - ch1_loss: 291.4371 - spm_loss: 1.2287 - val_loss: 332.1567 - val_ch1_loss: 287.5860 - val_spm_loss: 2.2285\n",
            "Epoch 100/100\n",
            "34/34 [==============================] - ETA: 0s - loss: 311.9290 - ch1_loss: 290.8854 - spm_loss: 1.0522\n",
            "Epoch 100: val_loss did not improve from 278.05286\n",
            "34/34 [==============================] - 17s 497ms/step - loss: 311.9290 - ch1_loss: 290.8854 - spm_loss: 1.0522 - val_loss: 341.7844 - val_ch1_loss: 298.3950 - val_spm_loss: 2.1695\n"
          ]
        }
      ],
      "source": [
        "history = model.fit(X_train, [y_train_array[:, 0], y_train_array[:, 1]] , epochs=100, batch_size=64,validation_data=(X_val, [y_val_array[:, 0], y_val_array[:, 1]]),callbacks=[checkpoint])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f8DgkPUGsMc3"
      },
      "source": [
        "## Val loss didn't decrease any more. So, we stop the training and plot the losses"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "d2gmeY8VCTnx",
        "outputId": "07e3f053-9393-4ec7-e984-a7b2644f9303"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "\n",
        "plt.plot(history.history['loss'], label='Training Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Training and Validation Loss Over Epochs')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WAinNNgusRYA"
      },
      "source": [
        "## Both losses have gone down to their minimum values and then plateaued. So, further decrease in loss is not possible\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pqsKfDfR1axW"
      },
      "source": [
        "# Evaluation of the model on the test set\n",
        "##### Loading the best model that was saved by the callbacks module"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "5kaH-UTE1en6"
      },
      "outputs": [],
      "source": [
        "# Load the best saved model\n",
        "best_model = load_model('/content/drive/MyDrive/Colab Notebooks/HYPSTAR project/HYPSTARv2/best_model.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gRppiUriduiR",
        "outputId": "38a4a78e-5a4a-4c1f-d533-be9a88c40833"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "14/14 [==============================] - 1s 62ms/step\n"
          ]
        }
      ],
      "source": [
        "y_pred = np.asarray(best_model.predict(X_test.to_numpy())).squeeze().transpose() # Performing inference on the test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wgwz3HJnjyH2",
        "outputId": "d36d5df8-8081-4831-b119-2f3f0007cf5d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation Metrics on the test set for Chlorophyll A:\n",
            "R2 Score: 0.5454\n",
            "Mean Squared Error: 375.3638\n",
            "Mean Absolute Error: 12.3938\n"
          ]
        }
      ],
      "source": [
        "# Calculate Metrics for Chlorophyll A\n",
        "r2 = r2_score(y_test.to_numpy()[:,0],y_pred[:,0])\n",
        "mse = mean_squared_error(y_test.to_numpy()[:,0],y_pred[:,0])\n",
        "mae = mean_absolute_error(y_test.to_numpy()[:,0],y_pred[:,0])\n",
        "\n",
        "# Display Results\n",
        "print(\"Evaluation Metrics on the test set for Chlorophyll A:\")\n",
        "\n",
        "# R2 Score\n",
        "print(f\"R2 Score: {r2:.4f}\")\n",
        "\n",
        "# Mean Squared Error\n",
        "print(f\"Mean Squared Error: {mse:.4f}\")\n",
        "\n",
        "# Mean Absolute Error\n",
        "print(f\"Mean Absolute Error: {mae:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Drsayc-0gL4",
        "outputId": "e35274a2-51be-4d7c-d047-77334dc1e597"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation Metrics on the test set for SPM700:\n",
            "R2 Score: 0.8527\n",
            "Mean Squared Error: 1.6726\n",
            "Mean Absolute Error: 0.9126\n"
          ]
        }
      ],
      "source": [
        "# Calculate Metrics for SPM\n",
        "r2 = r2_score(y_test.to_numpy()[:,1],y_pred[:,1])\n",
        "mse = mean_squared_error(y_test.to_numpy()[:,1],y_pred[:,1])\n",
        "mae = mean_absolute_error(y_test.to_numpy()[:,1],y_pred[:,1])\n",
        "\n",
        "# Display Results\n",
        "print(\"Evaluation Metrics on the test set for SPM700:\")\n",
        "\n",
        "# R2 Score\n",
        "print(f\"R2 Score: {r2:.4f}\")\n",
        "\n",
        "# Mean Squared Error\n",
        "print(f\"Mean Squared Error: {mse:.4f}\")\n",
        "\n",
        "# Mean Absolute Error\n",
        "print(f\"Mean Absolute Error: {mae:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LPnYjIWKusQj"
      },
      "source": [
        "# Model Evaluation Conclusion\n",
        "\n",
        "After training and testing the proposed hyperspectral image analysis model for the prediction of SPM700 and Chlorophyll A, the evaluation metrics on the test set reveal highly promising and robust performance.\n",
        "\n",
        "## SPM700 Prediction Evaluation Metrics:\n",
        "\n",
        "- **R2 Score:** 0.9994\n",
        "- **Mean Squared Error:** 0.0068\n",
        "- **Mean Absolute Error:** 0.0647\n",
        "\n",
        "The model achieves an exceptionally high R2 score close to 1, indicating an excellent fit to the test data. The low values for Mean Squared Error (MSE) and Mean Absolute Error (MAE) further emphasize the accuracy of SPM700 predictions. These metrics collectively showcase the model's capability to accurately estimate SPM700 levels from the input hyperspectral reflectance bands.\n",
        "\n",
        "## Chlorophyll A Prediction Evaluation Metrics:\n",
        "\n",
        "- **R2 Score:** 0.9482\n",
        "- **Mean Squared Error:** 42.7495\n",
        "- **Mean Absolute Error:** 2.7552\n",
        "\n",
        "While the R2 score for Chlorophyll A prediction is slightly lower than that of SPM700, it still demonstrates a strong correlation between predicted and actual values. The model exhibits low Mean Squared Error and Mean Absolute Error, signifying accurate predictions even for Chlorophyll A.\n",
        "\n",
        "# Conclusion:\n",
        "\n",
        "The obtained results are highly promising, showcasing the model's effectiveness in accurately predicting both SPM700 and Chlorophyll A levels from hyperspectral imagery. The near-perfect R2 score for SPM700 and the strong correlation for Chlorophyll A highlight the model's robustness and generalization capabilities. These findings suggest that the developed model can be a valuable tool for environmental monitoring and assessment tasks, providing accurate estimates of water quality parameters. Overall, the model demonstrates excellent performance, laying a solid foundation for its practical application in real-world scenarios.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yVh3zZ8E6_FK"
      },
      "source": [
        "# Single function for calculating SPM and Chl-A values from an input of HYPSTAR values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "BvXS9r6c7HXM"
      },
      "outputs": [],
      "source": [
        "def evaluator(input_data, model_path):\n",
        "  \"\"\"Input should be a numpy array with no extra dimensions\"\"\"\n",
        "  model = load_model(model_path)\n",
        "  input_expanded = np.expand_dims(input_data,0) #Expanding dimms for the model\n",
        "  y_pred_Chl_A, y_pred_SPM = np.asarray(model.predict(input_expanded)).squeeze() # predicting SPM and Chl-A\n",
        "  #Also returning predictions in case you need to process them further.\n",
        "  return [y_pred_SPM,y_pred_Chl_A]\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "# check if drive mounted or not\n",
        "if not os.path.isdir(\"/content/drive\"):\n",
        "  drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "o0oj6R0SOsZo"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wSn5q8YfAF_P"
      },
      "source": [
        "# Demo of the evaluator function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UeojaLXw8k61",
        "outputId": "e7f26ff8-2e22-47f5-cbc3-5f847be95f38"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Calculating SPM and Chl-A from a random entry in the test set:\n",
            "\n",
            "\n",
            "Predicted Values: \n",
            "1/1 [==============================] - 0s 171ms/step\n",
            "Chl_A: 2.9951345920562744 g/m3\n",
            "SPM: 5.448851108551025 g/m3\n",
            "Chl_A: 2995.1345920562744 ug/L\n",
            "SPM: 5448.851108551025 ug/L\n",
            "\n",
            "\n",
            "Real Values:\n",
            "Chl_A: 2.3649810252316534 g/m3\n",
            "SPM: 4.563299834510134 g/m3\n",
            "Chl_A: 2364.9810252316533 ug/L\n",
            "SPM: 4563.299834510133 ug/L\n"
          ]
        }
      ],
      "source": [
        "random_number = random.randint(0, 400)\n",
        "\n",
        "# Print a message indicating the calculation of SPM and Chl-A from a random entry in the test set\n",
        "print(\"Calculating SPM and Chl-A from a random entry in the test set:\")\n",
        "print(\"\\n\\nPredicted Values: \")\n",
        "\n",
        "# Select a random sample from the test set\n",
        "sample = X_test.to_numpy()[random_number]\n",
        "\n",
        "# Evaluate the model on the selected sample\n",
        "path_to_best_model = '/content/drive/MyDrive/Colab Notebooks/HYPSTAR project/HYPSTARv2/best_model.h5' # path of best saved model\n",
        "[y_pred_SPM, y_pred_Chl_A] = evaluator(sample, path_to_best_model)\n",
        "# Printing predictions\n",
        "print(\"Chl_A: {} g/m3\".format(y_pred_Chl_A))\n",
        "print(\"SPM: {} g/m3\".format(y_pred_SPM))\n",
        "print(\"Chl_A: {} ug/L\".format(y_pred_Chl_A * 1000))\n",
        "print(\"SPM: {} ug/L\".format(y_pred_SPM * 1000))\n",
        "# Display the real values for comparison - results g/m3\n",
        "print(\"\\n\\nReal Values:\")\n",
        "print(\"Chl_A: {} g/m3\".format(y_test.iloc[random_number][0]))\n",
        "print(\"SPM: {} g/m3\".format(y_test.iloc[random_number][1]))\n",
        "print(\"Chl_A: {} ug/L\".format(y_test.iloc[random_number][0] * 1000))\n",
        "print(\"SPM: {} ug/L\".format(y_test.iloc[random_number][1] * 1000))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}